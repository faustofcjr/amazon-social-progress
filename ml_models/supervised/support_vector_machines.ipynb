{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a9a4a4b-8446-41a0-82f5-43191188fe0b",
   "metadata": {},
   "source": [
    "```\n",
    "     _                                     ____             _       _   ____                                    \n",
    "    / \\   _ __ ___   __ _ _______  _ __   / ___|  ___   ___(_) __ _| | |  _ \\ _ __ ___   __ _ _ __ ___  ___ ___ \n",
    "   / _ \\ | '_ ` _ \\ / _` |_  / _ \\| '_ \\  \\___ \\ / _ \\ / __| |/ _` | | | |_) | '__/ _ \\ / _` | '__/ _ \\/ __/ __|\n",
    "  / ___ \\| | | | | | (_| |/ / (_) | | | |  ___) | (_) | (__| | (_| | | |  __/| | | (_) | (_| | | |  __/\\__ \\__ \\\n",
    " /_/   \\_\\_| |_| |_|\\__,_/___\\___/|_| |_| |____/ \\___/ \\___|_|\\__,_|_| |_|   |_|  \\___/ \\__, |_|  \\___||___/___/\n",
    "                                                                                        |___/                   \n",
    " Supervised Support vector machines (SVMs)\n",
    "```\n",
    "\n",
    "### Module\n",
    "__ExtraTreesClassifier__ implements a meta estimator that fits a number of randomized decision trees (a.k.a. extra-trees) on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "### Goal\n",
    "Ceate a model that combine the predictions of several decision trees estimators.\n",
    "\n",
    "### Tools\n",
    "1. Pandas\n",
    "2. scikit-learn\n",
    "3. SVM\n",
    "\n",
    "### Requirement\n",
    "1. File Definition\n",
    "2. Data Preparation\n",
    "3. hotspot_spi.csv generated\n",
    " \n",
    "### Data Source\n",
    "__${WORKDIR}__/data/ouptut/hotspot_spi.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18f52dfa-da1d-455d-9d4c-6b4a01e24c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import functions as func\n",
    "from  load_dataset import LoadDataset\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b83d15-716a-4295-8c7e-186fbd8c30f4",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f68bd6-6949-4b9d-8f10-5ceb55d99f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset = LoadDataset()\n",
    "X, y = load_dataset.return_X_y()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb1553-c378-4315-a433-69493411c75e",
   "metadata": {},
   "source": [
    "### Split dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f39f0dfd-92ae-4a40-9da5-6f0f8ac7a486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (1737, 49) y_train.shape: (1737,)\n",
      "X_test.shape: (579, 49) y_test.shape: (579,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape, \"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape:\", X_test.shape, \"y_test.shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017a663-57af-4210-af32-2adc18c35634",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b615c1df-73ab-44b7-99eb-a15e4162c80b",
   "metadata": {},
   "source": [
    "### Getting Best Hyperparameter Optimization\n",
    "\n",
    "*Note: The execution of the code below may take a few minutes or hours.*\n",
    "\n",
    "*Uncomment and run it when you need to optimize hyperparameters.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79c4204f-d072-449a-85b0-78fe84e55cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# space = dict()\n",
    "# space['kernel'] = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "# space['splitter'] = [\"best\", \"random\"]\n",
    "# space['n_estimators'] = [n for n in range(100)]\n",
    "# space['random_state'] = [n for n in range(10)]\n",
    "# space['max_depth'] = [n for n in range(20)]\n",
    "\n",
    "# func.show_best_hyperparameter_optimization(\n",
    "#     svm.SVC(), \n",
    "#     space, \n",
    "#     X_train, \n",
    "#     y_train\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e6b2c7-0e49-4dc6-b590-27f8c68a1dba",
   "metadata": {},
   "source": [
    "### Building, train and predict model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e6e1350-b8b6-4247-8c82-0d4feeb5e37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = svm.SVC(decision_function_shape=\"ovo\")\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    classifier\n",
    ")\n",
    "\n",
    "_ = pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695d1bdb-188b-4412-a66b-f68cce6314db",
   "metadata": {},
   "source": [
    "### Check the most relevant features for the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1159aff6-bc25-4480-bd39-19b64619071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# func.get_feature_importances(classifier, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f705f35-3a7e-4633-b698-7b4d41613006",
   "metadata": {},
   "source": [
    "### Predict and show model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d296d0e-c683-4428-8e5b-552815196bab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing cross-validated metrics\n",
      "----------------------------------------------------------------------\n",
      "Scores: [0.4375     0.47300216 0.46868251 0.47300216 0.44492441]\n",
      "Mean = 0.46 / Standard Deviation = 0.02\n",
      "\n",
      "Confunsion Matrix\n",
      "----------------------------------------------------------------------\n",
      "[[100   0  67   0   0]\n",
      " [  5   2  81   0  13]\n",
      " [ 45   0 115   0   5]\n",
      " [ 48   0   4  12   1]\n",
      " [  7   6  33   0  35]]\n",
      "\n",
      "Classification Report\n",
      "----------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.60      0.54       167\n",
      "           1       0.25      0.02      0.04       101\n",
      "           2       0.38      0.70      0.49       165\n",
      "           3       1.00      0.18      0.31        65\n",
      "           4       0.65      0.43      0.52        81\n",
      "\n",
      "    accuracy                           0.46       579\n",
      "   macro avg       0.55      0.39      0.38       579\n",
      "weighted avg       0.50      0.46      0.41       579\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Accuracy: 0.46\n",
      "Precicion: 0.46\n",
      "Sensitivity aka Recall: 0.46\n",
      "F1-Score: 0.46\n"
     ]
    }
   ],
   "source": [
    "y_predict = pipeline.predict(X_test)\n",
    "func.show_model_result(pipeline, X, y, y_test, y_predict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
